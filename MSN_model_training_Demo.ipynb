{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3d809-f203-4a2b-b6f4-93213cb59d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import models as M\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import backend as keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import trimesh\n",
    "import fpsample\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "import tensorflow_graphics as tfg\n",
    "from tensorflow_graphics.nn.loss import chamfer_distance\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3d049e-d9cb-48ef-a4be-52a887a74365",
   "metadata": {},
   "source": [
    "## Extracting Point clouds from meshes, extracting file names to create the dataset.\n",
    " - this will work directly with the download URL for the MSN dataset.\n",
    " - this might take a long time so you can try training the model on a smaller dataset or extract certain classes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db03f5-268c-4589-97f7-28f0904035de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "\n",
    "def normalize_point_cloud(point_cloud):\n",
    "    # Compute the mean of the point cloud\n",
    "    mean = np.mean(point_cloud, axis=0)\n",
    "\n",
    "    # Subtract the mean to move the point cloud to the origin\n",
    "    point_cloud -= mean\n",
    "\n",
    "    # Compute the maximum distance from the origin\n",
    "    max_distance = np.max(np.sqrt(np.sum(point_cloud**2, axis=1)))\n",
    "\n",
    "    # Scale the distances to the range -1.0 and 1.0\n",
    "    point_cloud /= max_distance\n",
    "\n",
    "    return point_cloud\n",
    "\n",
    "\n",
    "def process_and_save_point_clouds(links_url, point_cloud_dir='', num_points=6144):\n",
    "    \"\"\"\n",
    "    Fetches 3D mesh files from links provided in a text file, converts them to point clouds,\n",
    "    and saves the point clouds as PLY files.\n",
    "    \n",
    "    Args:\n",
    "        links_url (str): URL of the text file containing links to the 3D mesh files.\n",
    "        point_cloud_dir (str): Directory to save the point cloud PLY files.\n",
    "        num_points (int): Number of points to sample from each mesh to create the point cloud.\n",
    "    \"\"\"\n",
    "    # Step 1: Read the file containing the links\n",
    "    def read_links(url):\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        links = response.text.splitlines()\n",
    "        return links\n",
    "\n",
    "    links = read_links(links_url)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(point_cloud_dir, exist_ok=True)\n",
    "    \n",
    "    # Step 2: Convert the 3D meshes to point clouds directly from URLs\n",
    "    def mesh_to_point_cloud_from_url(url, num_points):\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        mesh = trimesh.load(BytesIO(response.content), file_type='stl')\n",
    "        points, _ = trimesh.sample.sample_surface(mesh, num_points)\n",
    "        return points\n",
    "\n",
    "    # Step 3: Save the point cloud as a PLY file\n",
    "    def save_point_cloud_as_ply(points, save_path):\n",
    "        point_cloud = trimesh.PointCloud(points)\n",
    "        point_cloud.export(save_path)\n",
    "\n",
    "    \n",
    "    #def save_point_cloud_as_txt(points, save_path):\n",
    "        #np.savetxt(save_path, points, delimiter=' ')\n",
    "\n",
    "    # Extract the file name from the URL\n",
    "    def extract_file_name(url):\n",
    "        parsed_url = urlparse(url)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        file_name = query_params.get('files', [None])[0]\n",
    "        return file_name\n",
    "\n",
    "    # Process each link, convert to point cloud and save as a PLY file\n",
    "    for url in links:\n",
    "        try:\n",
    "            file_name = extract_file_name(url)\n",
    "            if file_name is None:\n",
    "                print(f\"Failed to extract file name from {url}\")\n",
    "                continue\n",
    "            \n",
    "            point_cloud = mesh_to_point_cloud_from_url(url, num_points)\n",
    "            base_name = file_name.replace('.stl', '.ply')\n",
    "            point_cloud_path = os.path.join(point_cloud_dir, base_name)\n",
    "            save_point_cloud_as_ply(normalize_point_cloud(point_cloud), point_cloud_path)\n",
    "            #save_point_cloud_as_txt(normalize_point_cloud(point_cloud), point_cloud_path)\n",
    "            #print(f\"Saved point cloud to {point_cloud_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22efca84-4e51-4056-9f85-95f468d070df",
   "metadata": {},
   "source": [
    "## Utility functions for data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57737dce-2792-4d40-b995-d5aa6028c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_knn_points_by_index(points, point_index, num_remove):\n",
    "    center_point = points[point_index]\n",
    "    distances = np.linalg.norm(points - center_point, axis=1)\n",
    "    knn_indices = np.argsort(distances)[:num_remove]\n",
    "    remaining_points = np.delete(points, knn_indices, axis=0)\n",
    "    return remaining_points\n",
    "\n",
    "\n",
    "def preprocess_data(root_folder):\n",
    "    \"\"\"\n",
    "    Preprocesses point cloud data and text labels for training by generating input sets, eye seeds,\n",
    "    tokenized text, and ground truth sets from 3D mesh files.\n",
    "\n",
    "    Args:\n",
    "        root_folder (str): The root directory containing .ply files with point clouds.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing six lists:\n",
    "            - input_set (list): List of partial point clouds generated from the meshes.\n",
    "            - eye_seeds (list): Randomly generated eye seeds for each point cloud.\n",
    "            - text_set (list): List of text labels (class names) for each mesh.\n",
    "            - input_ids (list): List of tokenized text input IDs.\n",
    "            - attention_masks (list): List of attention masks for the tokenized text.\n",
    "            - GT_set (list): Ground truth (full) point clouds.\n",
    "    \"\"\"\n",
    "    input_set = []\n",
    "    eye_seeds = []\n",
    "    text_set = []\n",
    "    GT_set = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.ply'):\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                class_name_part = base_name.split('_', 1)[1]\n",
    "                class_name = class_name_part.split('.')[0]\n",
    "                class_name = class_name.replace('_', ' ')\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "\n",
    "                # Load the mesh and sample the ground truth points\n",
    "                mesh = trimesh.load(file_path)\n",
    "                GT = np.array(mesh.vertices)\n",
    "                GT_idx = fpsample.fps_sampling(GT, 6144, start_idx=0)\n",
    "                GT = GT[GT_idx]\n",
    "\n",
    "                # Generate partial point clouds using farthest point sampling\n",
    "                indices = fpsample.fps_sampling(GT, 2, start_idx=0)\n",
    "                for idx in indices:\n",
    "                    partial_cloud = remove_knn_points_by_index(GT, idx, 2048)\n",
    "                    input_set.append(partial_cloud)\n",
    "                    eye_seeds.append(np.random.rand(1, 1))\n",
    "                    text_set.append(class_name)\n",
    "                    GT_set.append(GT)\n",
    "\n",
    "    # Step 4: Tokenize the text using BERT tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    encoded_inputs = tokenizer.batch_encode_plus(\n",
    "        text_set,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    input_ids = encoded_inputs['input_ids']\n",
    "    attention_masks = encoded_inputs['attention_mask']\n",
    "\n",
    "    return np.array(input_set, dtype= np.float32), np.array(eye_seeds, dtype= np.float32), np.array(input_ids, dtype= np.int32), np.array(attention_masks, dtype= np.int32), np.array(GT_set, dtype= np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc4456-a9b4-40f7-9e3f-10c5bc508c22",
   "metadata": {},
   "source": [
    "## loss functions\n",
    " - Code for the Density aware chamfer distance loss (DCD) \n",
    " - code for the Vanilla chamfer distance (CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965db67-ee57-45ee-b517-53473a45b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_seed(X):\n",
    "    return tf.zeros([X.shape[0],1,1])\n",
    "\n",
    "def distance_matrix(array1, array2):\n",
    "    batch_size, num_point, num_features = array1.shape\n",
    "    expanded_array1 = tf.tile(tf.expand_dims(array1, 2), [1, 1, num_point, 1])\n",
    "    expanded_array2 = tf.tile(tf.expand_dims(array2, 1), [1, num_point, 1, 1])\n",
    "    distances = tf.norm(expanded_array1-expanded_array2, axis=-1)\n",
    "    return distances\n",
    "\n",
    "def min_distances_and_indices(array1, array2):\n",
    "    distances = distance_matrix(array1, array2)\n",
    "    min_dists_1_to_2, indices_1_to_2 = tf.reduce_min(distances, axis=-1), tf.argmin(distances, axis=-1)\n",
    "    min_dists_2_to_1, indices_2_to_1 = tf.reduce_min(distances, axis=-2), tf.argmin(distances, axis=-2)\n",
    "    return min_dists_1_to_2, min_dists_2_to_1, indices_1_to_2, indices_2_to_1\n",
    "\n",
    "def calc_cd(output, gt, calc_f1=False, return_raw=False, normalize=False, separate=False):\n",
    "    dist1, dist2, idx1, idx2 = min_distances_and_indices(gt, output)\n",
    "    cd_p = (tf.sqrt(tf.reduce_mean(dist1, axis=1)) + tf.sqrt(tf.reduce_mean(dist2, axis=1))) / 2\n",
    "    cd_t = (tf.reduce_mean(dist1, axis=1) + tf.reduce_mean(dist2, axis=1))\n",
    "    if separate:\n",
    "        res = [tf.concat([tf.reduce_mean(tf.sqrt(dist1), axis=1, keepdims=True),\n",
    "                          tf.reduce_mean(tf.sqrt(dist2), axis=1, keepdims=True)], axis=0),\n",
    "               tf.concat([tf.reduce_mean(dist1, axis=1, keepdims=True),\n",
    "                          tf.reduce_mean(dist2, axis=1, keepdims=True)], axis=0)]\n",
    "    else:\n",
    "        res = [cd_p, cd_t]\n",
    "    if calc_f1:\n",
    "        f1, _, _ = fscore(dist1, dist2, 0.0001)\n",
    "        res.append(f1)\n",
    "    if return_raw:\n",
    "        res.extend([dist1, dist2, idx1, idx2])\n",
    "    return res\n",
    "\n",
    "def calc_dcd(x, gt, alpha=1, n_lambda=1, return_raw=False, non_reg=False):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    gt = tf.cast(gt, tf.float32)\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    n_x = tf.shape(x)[1]\n",
    "    n_gt = tf.shape(gt)[1]\n",
    "    if non_reg:\n",
    "        frac_12 = tf.maximum(1.0, tf.cast(n_x, tf.float32) / tf.cast(n_gt, tf.float32))\n",
    "        frac_21 = tf.maximum(1.0, tf.cast(n_gt, tf.float32) / tf.cast(n_x, tf.float32))\n",
    "    else:\n",
    "        frac_12 = tf.cast(n_x, tf.float32) / tf.cast(n_gt, tf.float32)\n",
    "        frac_21 = tf.cast(n_gt, tf.float32) / tf.cast(n_x, tf.float32)\n",
    "    cd_p, cd_t, dist1, dist2, idx1, idx2 = calc_cd(x, gt, return_raw=True)\n",
    "    exp_dist1 = tf.exp(-dist1 * alpha)\n",
    "    exp_dist2 = tf.exp(-dist2 * alpha)\n",
    "    def compute_loss(b):\n",
    "        idx1_b = tf.gather(idx1, b)\n",
    "        idx2_b = tf.gather(idx2, b)\n",
    "        count1 = tf.math.bincount(idx1_b, minlength=tf.cast(n_x, tf.int64))\n",
    "        weight1 = tf.gather(count1, idx1_b)\n",
    "        weight1 = tf.cast(weight1, tf.float32)\n",
    "        weight1 = tf.pow(weight1, n_lambda)\n",
    "        weight1 = tf.pow((weight1 + 1e-6), -1) * frac_21\n",
    "        loss1 = tf.reduce_mean(-exp_dist1[b] * weight1 + 1.0)\n",
    "        count2 = tf.math.bincount(idx2_b, minlength=tf.cast(n_gt, tf.int64))\n",
    "        weight2 = tf.gather(count2, idx2_b)\n",
    "        weight2 = tf.cast(weight2, tf.float32)\n",
    "        weight2 = tf.pow(weight2, n_lambda)\n",
    "        weight2 = tf.pow((weight2 + 1e-6), -1) * frac_12\n",
    "        loss2 = tf.reduce_mean(-exp_dist2[b] * weight2 + 1.0)\n",
    "        return loss1, loss2\n",
    "    loss1, loss2 = tf.map_fn(compute_loss, tf.range(batch_size), dtype=(tf.float32, tf.float32))\n",
    "    loss = tf.reduce_mean(loss1 + loss2)\n",
    "    res = [loss, cd_p, cd_t]\n",
    "    if return_raw:\n",
    "        res.extend([dist1, dist2, idx1, idx2])\n",
    "    return loss\n",
    "\n",
    "def chamfer_distance_loss(y_true, y_pred):\n",
    "    return tfg.nn.loss.chamfer_distance.evaluate(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f1021-9a69-4f0a-b89e-9cdedaad522f",
   "metadata": {},
   "source": [
    "## Utility functions for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f496c4dd-f6f6-41d0-b423-10d48c86530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(xyz1, xyz2):\n",
    "    n = xyz1.shape[1]\n",
    "    c = xyz1.shape[2]\n",
    "    m = xyz2.shape[1]\n",
    "    xyz1 = tf.tile(tf.reshape(xyz1, (-1,1,n,c)), [1,m,1,1])\n",
    "    xyz2 = tf.tile(tf.reshape(xyz2, (-1,m,1,c)), [1,1,n,1])\n",
    "    dist = tf.reduce_sum((xyz1-xyz2)**2, -1)\n",
    "    return dist\n",
    "\n",
    "def knn_point(k, xyz1, xyz2):\n",
    "    dist = -pairwise_distance(xyz1, xyz2)\n",
    "    val, idx = tf.math.top_k(dist, k)\n",
    "    return -val, idx\n",
    "\n",
    "class UniformSampler(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_points, seed=42, **kwargs):\n",
    "        super(UniformSampler, self).__init__(**kwargs)\n",
    "        self.num_points = num_points\n",
    "        self.seed = seed\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        data_size = tf.shape(inputs)[1]\n",
    "        indices = tf.random.uniform(\n",
    "            shape=(batch_size, self.num_points),\n",
    "            minval=0,\n",
    "            maxval=data_size,\n",
    "            dtype=tf.int32,\n",
    "            seed=self.seed\n",
    "        )\n",
    "        return indices\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.num_points, input_shape[2])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(UniformSampler, self).get_config()\n",
    "        config.update({\n",
    "            \"num_points\": self.num_points,\n",
    "            \"seed\": self.seed\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def sample_and_group(args, nsample):\n",
    "    xyz, pts, fps_idx = args\n",
    "    new_xyz = tf.gather_nd(xyz, tf.expand_dims(fps_idx,-1), batch_dims=1)\n",
    "    new_pts = tf.gather_nd(pts, tf.expand_dims(fps_idx,-1), batch_dims=1)\n",
    "    _, idx = knn_point(nsample, xyz, new_xyz)\n",
    "    grouped_pts = tf.gather_nd(pts, tf.expand_dims(idx,-1), batch_dims=1)\n",
    "    grouped_pts -= tf.tile(tf.expand_dims(new_pts, 2),\n",
    "                           (1,1,nsample,1))\n",
    "    new_pts = tf.concat([grouped_pts,\n",
    "                         tf.tile(tf.expand_dims(new_pts, 2),\n",
    "                                 (1,1,nsample,1))],\n",
    "                        axis=-1)\n",
    "    return new_xyz, new_pts\n",
    "\n",
    "def LBR(tensor, C, seq_name, use_bias=True, activation=None, LeakyAlpha=0.0):\n",
    "    x_in = Input(shape=tensor.shape[1:], name=seq_name+'_input')\n",
    "    x = L.Dense(C, use_bias=use_bias, activation=activation, name=seq_name+'_lin')(x_in)\n",
    "    if LeakyAlpha==0.0:\n",
    "        x_out = L.ReLU(name=seq_name+'_ReLU')(x)\n",
    "    else:\n",
    "        x_out = L.LeakyReLU(alpha=LeakyAlpha, name=seq_name+'_ReLU')(x)\n",
    "    model = M.Model(inputs=x_in, outputs=x_out, name=seq_name)\n",
    "    return model(tensor)\n",
    "\n",
    "def Self_Attention(tensor, seq_name):\n",
    "    x_in = Input(shape=tensor.shape[1:], name=seq_name+'_input')\n",
    "    C = x_in.shape[2]\n",
    "    W_q = L.Dense(C//4, use_bias=False, activation=None, name=seq_name+'_Q')\n",
    "    W_k = L.Dense(C//4, use_bias=False, activation=None, name=seq_name+'_K')\n",
    "    W_v = L.Dense(C, use_bias=False, activation=None, name=seq_name+'_V')\n",
    "    x_q = W_q(x_in)\n",
    "    x_k = W_k(x_in)\n",
    "    W_k.set_weights(W_q.get_weights())\n",
    "    x_k = L.Lambda(lambda t: tf.transpose(t, perm=(0,2,1)), name=seq_name+'_KT')(x_k)\n",
    "    x_v = W_v(x_in)\n",
    "    energy = L.Lambda(lambda ts: tf.matmul(ts[0],ts[1]), name=seq_name+'_matmul1')([x_q, x_k])\n",
    "    attention = L.Softmax(axis=1, name=seq_name+'_softmax')(energy)\n",
    "    attention = L.Lambda(lambda t: t / (1e-9 + tf.reduce_sum(t, axis=2, keepdims=True)), name=seq_name+'_l1norm')(attention)\n",
    "    x_r = L.Lambda(lambda ts: tf.matmul(ts[0],ts[1]), name=seq_name+'_matmul2')([attention, x_v])\n",
    "    x_r = L.Lambda(lambda ts: tf.subtract(ts[0],ts[1]), name=seq_name+'_subtract')([x_in, x_r])\n",
    "    x_r = LBR(x_r, C, seq_name+'_LBR', use_bias=True)\n",
    "    x_out = L.Lambda(lambda ts: tf.add(ts[0],ts[1]), name=seq_name+'_add')([x_in, x_r])\n",
    "    model = M.Model(inputs=x_in, outputs=x_out, name=seq_name)\n",
    "    return model(tensor)\n",
    "\n",
    "\n",
    "def Cross_Attention(args, seq_name):\n",
    "    E_tensor, D_tensor = args\n",
    "    xE_in = Input(shape=E_tensor.shape[1:], name=seq_name+'_input-E')\n",
    "    C = xE_in.shape[2]\n",
    "    xD_in = Input(shape=D_tensor.shape[1:], name=seq_name+'_input-D')\n",
    "    out_dim = xD_in.shape[2]\n",
    "    W_q = L.Dense(C//4, use_bias=False, activation=None, name=seq_name+'_Q')\n",
    "    W_k = L.Dense(C//4, use_bias=False, activation=None, name=seq_name+'_K')\n",
    "    W_v = L.Dense(out_dim, use_bias=False, activation=None, name=seq_name+'_V')\n",
    "    x_q = W_q(xD_in)\n",
    "    x_k = W_k(xE_in)\n",
    "    x_k = L.Lambda(lambda t: tf.transpose(t, perm=(0,2,1)), name=seq_name+'_KT')(x_k)\n",
    "    x_v = W_v(xE_in)\n",
    "    energy = L.Lambda(lambda ts: tf.matmul(ts[0],ts[1]), name=seq_name+'_matmul1')([x_q, x_k])\n",
    "    attention = L.Softmax(axis=1, name=seq_name+'_softmax')(energy)\n",
    "    attention = L.Lambda(lambda t: t / (1e-9 + tf.reduce_sum(t, axis=2, keepdims=True)), name=seq_name+'_l1norm')(attention)\n",
    "    x_r = L.Lambda(lambda ts: tf.matmul(ts[0],ts[1]), name=seq_name+'_matmul2')([attention, x_v])\n",
    "    x_r = L.Lambda(lambda ts: tf.subtract(ts[0],ts[1]), name=seq_name+'_subtract')([xD_in, x_r])\n",
    "    x_r = LBR(x_r, out_dim, seq_name+'_LBR', use_bias=True)\n",
    "    x_out = L.Lambda(lambda ts: tf.add(ts[0],ts[1]), name=seq_name+'_add')([xD_in, x_r])\n",
    "    model = M.Model(inputs=[xE_in,xD_in], outputs=x_out, name=seq_name)\n",
    "    return model([E_tensor,D_tensor])\n",
    "\n",
    "def copy_and_mapping(tensor, nmul, seq_name):\n",
    "    x_in = Input(shape=tensor.shape[1:], name=seq_name+'_input')\n",
    "    x = L.Lambda(lambda t: tf.expand_dims(t, 2), name=seq_name+'_expand')(x_in)\n",
    "    C = x.shape[-1]//nmul\n",
    "    x1 = L.Conv2DTranspose(C,(1,nmul),(1,nmul), use_bias=True, activation=None, name=seq_name+'_convT')(x)\n",
    "    x2 = L.Dense(C, use_bias=True, activation=None, name=seq_name+'_lin')(x)\n",
    "    x2 = L.Lambda(lambda t: tf.tile(t, [1,1,nmul,1]), name=seq_name+'_tile')(x2)\n",
    "    x = L.Lambda(lambda ts: tf.add(ts[0],ts[1]), name=seq_name+'_add')([x1, x2])\n",
    "    npoint = x.shape[1]*x.shape[2]\n",
    "    x_out = L.Lambda(lambda t: tf.reshape(t, [-1,npoint,t.shape[3]]), name=seq_name+'_reshape')(x)\n",
    "    model = M.Model(inputs=x_in, outputs=x_out, name=seq_name)\n",
    "    return model(tensor)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e6dfe-3ef4-494a-8b28-1943bc73835a",
   "metadata": {},
   "source": [
    "## Point Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64333d1f-a9ba-4bab-b610-ccb184911a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCT_encoder(xyz):\n",
    "    x = LBR(xyz, 64, 'E-IN_LBR1', use_bias=False)\n",
    "    x = LBR(x, 128, 'E-IN_LBR2', use_bias=False)\n",
    "    fps_idx = UniformSampler(4096)(xyz)\n",
    "    new_xyz, new_feature = L.Lambda(sample_and_group, arguments={'nsample':32}, name='E-SG1')([xyz, x, fps_idx])\n",
    "    x = LBR(new_feature, 512, 'E-SG1_LBR1', use_bias=False)\n",
    "    x = L.Lambda(lambda t: tf.reduce_max(t, axis=2), name='E-SG1_MaxPool')(x)\n",
    "    fps_idx = UniformSampler(2048)(new_xyz)\n",
    "    new_xyz, new_feature = L.Lambda(sample_and_group, arguments={'nsample':32}, name='E-SG2')([new_xyz, x, fps_idx])\n",
    "    x = LBR(new_feature, 1024, 'E-SG2_LBR1', use_bias=False)\n",
    "    x = L.Lambda(lambda t: tf.reduce_max(t, axis=2), name='E-SG2_MaxPool')(x)\n",
    "    x1 = Self_Attention(x, 'E-SA1')\n",
    "    x2 = Self_Attention(x1, 'E-SA2')\n",
    "    x3 = Self_Attention(x2, 'E-SA3')\n",
    "    x4 = Self_Attention(x3, 'E-SA4')\n",
    "    x0 = L.Lambda(lambda ts: tf.concat(ts, axis=2), name='E-SA_Concat')([x1,x2,x3,x4])\n",
    "    x = L.Lambda(lambda ts: tf.concat(ts, axis=2), name='E-OUT_Concat')([x0,x])\n",
    "    x = LBR(x, 2048, 'E-OUT_LBR', use_bias=False, LeakyAlpha=0.2)\n",
    "    x1 = Self_Attention(x, 'E-SA5')\n",
    "    x2 = Self_Attention(x1, 'E-SA6')\n",
    "    x3 = Self_Attention(x2, 'E-SA7')\n",
    "    x4 = Self_Attention(x3, 'E-SA8')\n",
    "    x0 = L.Lambda(lambda ts: tf.concat(ts, axis=2), name='E-SA_Concat2')([x1,x2,x3,x4])\n",
    "    x = LBR(x0, 4096, 'E-OUT_LBR1', use_bias=False, LeakyAlpha=0.2)\n",
    "    output_feats = L.Lambda(lambda t: tf.reduce_max(t, axis=1, keepdims=True), name='E-OUT_MaxPool')(x)\n",
    "    return output_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6fabb7-2126-48d5-861a-9e461da8a4c6",
   "metadata": {},
   "source": [
    "## Point Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af95f1e-5079-47d3-bffa-e304f69c1807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_decoder(input_feats, input_eye_seed):\n",
    "    m_feats = L.Lambda(lambda x: tf.tile(x, [1,1024,1]), name = 'D-IN_replicate')(input_feats)\n",
    "    input_eye = input_eye_seed + tf.eye(1024,1024)\n",
    "    x = L.Dense(4096//4, use_bias=False, activation=None, name='D1-IN')(input_eye)\n",
    "    x1 = Cross_Attention([m_feats,x] , 'D-STA1')\n",
    "    x2 = Cross_Attention([m_feats,x1], 'D-STA2')\n",
    "    x3 = Cross_Attention([m_feats,x2], 'D-STA3')\n",
    "    x4 = Cross_Attention([m_feats,x3], 'D-STA4')\n",
    "    x0 = L.Lambda(lambda ts: tf.concat(ts, axis=2), name='D1-STA_Concat')([x1,x2,x3,x4])\n",
    "    x = L.Lambda(lambda ts: tf.concat(ts, axis=2), name='D1-OUT_Concat')([x0,x])\n",
    "    m_feats2 = copy_and_mapping(x, 3, 'D1-OUT_CopyAndMapping')\n",
    "    input_eye2 = input_eye_seed + tf.eye(3072,3072)\n",
    "    x = L.Dense(1024//4, use_bias=False, activation=None, name='D2-IN')(input_eye2)\n",
    "    x1 = Cross_Attention([m_feats2,x] , 'D2-STA1')\n",
    "    x2 = Cross_Attention([m_feats2,x1], 'D2-STA2')\n",
    "    x3 = Cross_Attention([m_feats2,x2], 'D2-STA3')\n",
    "    x4 = Cross_Attention([m_feats2,x3], 'D2-STA4')\n",
    "    x0 = L.Lambda(lambda ts: tf.concat(ts, axis=2), name='D2-STA_Concat')([x1,x2,x3,x4])\n",
    "    x = L.Lambda(lambda ts: tf.concat(ts, axis=2), name='D2-OUT_Concat')([x0,x])\n",
    "    x = copy_and_mapping(x, 2, 'D2-OUT_CopyAndMapping')\n",
    "    x = LBR(x,128, 'D-OUT_LBR1', use_bias=False)\n",
    "    x = LBR(x,128, 'D-OUT_LBR2', use_bias=False)\n",
    "    x = LBR(x, 64, 'D-OUT_LBR3', use_bias=False, LeakyAlpha=0.2)\n",
    "    output_points = L.Dense(3, activation=None, name='D-OUT_lin')(x)\n",
    "    return output_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b107f-36fc-4dba-ae2b-ba3d486aa4ab",
   "metadata": {},
   "source": [
    "## Bert Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878280e-bd0a-4fb9-9851-90e3578f7044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_model(input_ids, attention_mask, model_name='bert-base-uncased', max_length=128):\n",
    "    bert_model = TFBertModel.from_pretrained(model_name)\n",
    "    bert_model.trainable = False\n",
    "    bert_outputs = bert_model([input_ids, attention_mask])\n",
    "    cls_output = bert_outputs.pooler_output\n",
    "    dense_output = tf.keras.layers.Dense(4096, activation='relu')(cls_output)\n",
    "    output = tf.expand_dims(dense_output, axis = 1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63921720-6c74-4f26-8782-e466159dc339",
   "metadata": {},
   "source": [
    "## Building the Multi-modal point cloud autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19256f-69c6-435f-abf9-0537b4bb9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCT_AE_Multimodal:\n",
    "    def __init__(self, num_input_points=4096, max_length=128, bert_model=bert_model, PCT_encoder=PCT_encoder, pct_decoder=pct_decoder):\n",
    "        self.num_input_points = num_input_points\n",
    "        self.max_length = max_length\n",
    "        self.bert_model = bert_model\n",
    "        self.PCT_encoder = PCT_encoder\n",
    "        self.pct_decoder = pct_decoder\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        eye_seed = Input(shape=(1, 1), name='input_eye_seed')\n",
    "        xyz = Input(shape=(self.num_input_points, 3), name='input_points')\n",
    "        input_ids = Input(shape=(self.max_length,), dtype=tf.int32, name='input_ids')\n",
    "        attention_mask = Input(shape=(self.max_length,), dtype=tf.int32, name='attention_mask')\n",
    "        if not self.bert_model or not self.PCT_encoder or not self.pct_decoder:\n",
    "            raise ValueError(\"Bert model, PCT encoder, and PCT decoder must be provided.\")\n",
    "        text_encoded = self.bert_model(input_ids, attention_mask)\n",
    "        cloud_encoded = self.PCT_encoder(xyz)\n",
    "        multi_encoded = cloud_encoded + text_encoded\n",
    "        output = self.pct_decoder(multi_encoded, eye_seed)\n",
    "        return M.Model(inputs=[xyz, eye_seed, input_ids, attention_mask], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb565f9-ec06-49fb-9227-c00fa2fe3fbf",
   "metadata": {},
   "source": [
    "## Instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b7ecd-357d-468c-af0e-cfd57ae2fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AE = PCT_AE_Multimodal(bert_model=bert_model, PCT_encoder=PCT_encoder, pct_decoder=pct_decoder)\n",
    "AE = AE.model\n",
    "initial_learning_rate = 1e-7\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "AE.compile(optimizer=optimizer, loss=calc_dcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c7151-4e87-44b9-be21-16f6f21d3c90",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2d7b06-aaa4-4ec8-b70f-d66a0a2edf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"path/to/your/ply/files\"\n",
    "\n",
    "# Call the preprocess_data function\n",
    "input_set, eye_seeds, input_ids, attention_masks, GT_set = preprocess_data(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357db96-d723-4082-b45c-9ba3519f9d96",
   "metadata": {},
   "source": [
    "## Defining callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe0962-e529-414a-9569-07466e66116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.9,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    min_lr=1e-20\n",
    ")\n",
    "\n",
    "save_dir = 'path/to/your/directory'\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(save_dir, 'weights_file_name.h5'),\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ea63c-5bb6-4dfb-9c9e-7476d7ef36aa",
   "metadata": {},
   "source": [
    "### Model Training Overview\n",
    " -Training was performed over six weeks on 6 NVIDIA RTX A6000 GPUs (40 GB VRAM each) and 8 CPUs with 1000 GB of RAM. \n",
    "\n",
    " -After 322 epochs, training was stopped due to no performance improvements for 12 consecutive epochs. We used the ADAM optimizer with an initial learning rate of 1e-7. To enhance efficiency, the ReduceLROnPlateau callback was employed, dynamically reducing the learning rate based on validation performance, aiding model convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c54ad2-7e77-4b52-9b2c-02e8803209d7",
   "metadata": {},
   "outputs": [],
   "source": [
    " AE.fit([input_set, eye_seeds, input_ids, attention_masks], GT_set, epochs=500,\n",
    "           shuffle=True, validation_split=0.1, batch_size=8, verbose=1,\n",
    "           callbacks=[reduce_lr, checkpoint_callback])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
